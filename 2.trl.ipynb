{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e605849-0522-4bd5-8cd8-9e5c73362417",
   "metadata": {},
   "source": [
    "# trl 微调\n",
    "\n",
    "[trl](https://github.com/huggingface/trl) 的功能强大，支持 SFT, PPO, DPO, GRPO 等微调方法。并且有良好的生态支持，比如，trl 可以配合 [peft](https://github.com/huggingface/peft) 的 `LoraConfig` 模块定义 LoRA 参数；配合 [unsloth](https://github.com/unslothai/unsloth) 的 `FastLanguageModel` 模型加载模型。\n",
    "\n",
    "与上一节的 LLaMA Factory 相比，trl 可以更精细地定义训练中的行为。比如，如何加载数据集、如何构建损失函数、允许哪些参数层参与训练等等。适合需要深度控制训练过程的场景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "031357e1-ea57-4e34-b3d6-cd4bb6f2efc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:15:09.884236Z",
     "iopub.status.busy": "2025-04-21T19:15:09.884031Z",
     "iopub.status.idle": "2025-04-21T19:15:09.888433Z",
     "shell.execute_reply": "2025-04-21T19:15:09.887303Z",
     "shell.execute_reply.started": "2025-04-21T19:15:09.884219Z"
    }
   },
   "outputs": [],
   "source": [
    "# !uv pip install --upgrade transformers\n",
    "# !uv pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "376d8dba-ea86-4d7d-91f8-f223f4f82fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:15:09.889242Z",
     "iopub.status.busy": "2025-04-21T19:15:09.889064Z",
     "iopub.status.idle": "2025-04-21T19:15:18.241486Z",
     "shell.execute_reply": "2025-04-21T19:15:18.241150Z",
     "shell.execute_reply.started": "2025-04-21T19:15:09.889225Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "DATASET_PATH = './data/train_zh_1000.json'\n",
    "MODEL_PATH = './model/Qwen/Qwen2.5-7B-Instruct/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e150d-f756-4fbe-87ee-3a74284856d3",
   "metadata": {},
   "source": [
    "## 1. 加载数据集\n",
    "\n",
    "上一节，我们将医疗数据集 [shibing624/medical](https://huggingface.co/datasets/shibing624/medical) 保存到 `data` 目录，并采样生成了 `train_zh_1000.json` 文件。\n",
    "\n",
    "本节，我们用 `datasets` 的 `load_dataset` 方法加载 `train_zh_1000.json` 文件。关于 `load_dataset` 的数据处理逻辑，详见：[https://huggingface.co/docs/datasets/loading](https://huggingface.co/docs/datasets/loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a61559-3b97-4b1d-b179-d645adb7acc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:15:18.242143Z",
     "iopub.status.busy": "2025-04-21T19:15:18.241874Z",
     "iopub.status.idle": "2025-04-21T19:15:31.598136Z",
     "shell.execute_reply": "2025-04-21T19:15:31.597430Z",
     "shell.execute_reply.started": "2025-04-21T19:15:18.242134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基本信息：\n",
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output'],\n",
      "    num_rows: 1000\n",
      "})\n",
      "数据集的行数：\n",
      "1000\n",
      "数据集的形状：\n",
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# 从 HuggingFace 仓库加载数据集\n",
    "# dataset = load_dataset(\"trl-lib/Capybara\", split=\"train\")\n",
    "\n",
    "# 从本地加载数据集\n",
    "dataset = load_dataset(\"json\", data_files=DATASET_PATH)['train']\n",
    "\n",
    "# 打印数据集的基本信息\n",
    "print(f'基本信息：\\n{dataset}')\n",
    "\n",
    "# 查看数据集的行数\n",
    "print(f'数据集的行数：\\n{dataset.num_rows}')\n",
    "\n",
    "# 查看数据集的形状\n",
    "print(f'数据集的形状：\\n{dataset.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b0c124-0db9-4f26-ba75-9f19aeb50837",
   "metadata": {},
   "source": [
    "## 2. 微调 Qwen 模型\n",
    "\n",
    "对模型使用 4-bit 量化，并用半精度浮点数加载模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca490e9-ac1a-403e-8920-654d241bdcb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:15:31.599061Z",
     "iopub.status.busy": "2025-04-21T19:15:31.598714Z",
     "iopub.status.idle": "2025-04-21T19:39:51.927454Z",
     "shell.execute_reply": "2025-04-21T19:39:51.926577Z",
     "shell.execute_reply.started": "2025-04-21T19:15:31.599043Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34dc14c6c984ce0a57464d6ce3d651c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 量化配置\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090203fe-7d0d-4def-9d9d-6ebfa6d4371c",
   "metadata": {},
   "source": [
    "我们加载的数据集是 alpaca 格式的。下面使用 `formatting_prompts_func` 函数，将数据转换成如下格式的文本：\n",
    "\n",
    "```\n",
    "### Question:\n",
    "{your_question}\n",
    "\n",
    "### Answer:\n",
    "{your_answer}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3ead01-ce49-4454-baeb-3a639f1f1d3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:39:51.928905Z",
     "iopub.status.busy": "2025-04-21T19:39:51.928509Z",
     "iopub.status.idle": "2025-04-21T19:39:51.933198Z",
     "shell.execute_reply": "2025-04-21T19:39:51.932570Z",
     "shell.execute_reply.started": "2025-04-21T19:39:51.928882Z"
    }
   },
   "outputs": [],
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        text = f\"### Question: {example['instruction'][i]}\\n ### Answer: {example['output'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20704b59-9d90-42e6-a432-0f79322d5c5d",
   "metadata": {},
   "source": [
    "本次微调采用 `Train on completions only` 方法（仅对模型生成的 `### Answer:` 之后的部分计算损失）。什么意思呢？如果没有额外配置，我们将计算整个句子的损失，既计算 `Question` 的损失，也计算 `Answer` 的损失。这显然是不合理的。既然不用推理 `Question`，就不应该计算 `Question` 的损失。若将 `Question` 的损失加入训练，浪费算力不说，模型的优化目标也会产生偏差，导致训练效果变差。\n",
    "\n",
    "为了达到仅计算 `Answer` 部分的损失的效果，下面用 `DataCollatorForCompletionOnlyLM` 定位样本数据 `Answer` 部分的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b75c2d1-850c-4288-b502-9627dc73bb3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:39:51.934840Z",
     "iopub.status.busy": "2025-04-21T19:39:51.934552Z",
     "iopub.status.idle": "2025-04-21T19:39:52.411439Z",
     "shell.execute_reply": "2025-04-21T19:39:52.410994Z",
     "shell.execute_reply.started": "2025-04-21T19:39:51.934827Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "response_template = \" ### Answer:\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97956743-4346-40b7-bab8-05ad71651a61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T16:06:45.577002Z",
     "iopub.status.busy": "2025-04-21T16:06:45.575720Z",
     "iopub.status.idle": "2025-04-21T16:06:45.593988Z",
     "shell.execute_reply": "2025-04-21T16:06:45.591977Z",
     "shell.execute_reply.started": "2025-04-21T16:06:45.576955Z"
    }
   },
   "source": [
    "我的五星级神机显存高达 8G，因此选择了较小的秩和缩放系数。如果你的 GPU 比较厉害，可以把秩和缩放系数设置得大一点，这有利于提高微调精度。比如可以设置成：\n",
    "\n",
    "```\n",
    "r=16,\n",
    "lora_alpha=32,\n",
    "```\n",
    "\n",
    "`target_modules` 参数用于指定 LoRA 微调生效的模块，比较推荐微调以下模块：\n",
    "\n",
    "- 注意力相关：\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"\n",
    "- GLU 相关：\"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "\n",
    "> 亦可参考官方文档的 `peft_config` 配置：[training-adapters](https://huggingface.co/docs/trl/sft_trainer#training-adapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca780e90-af11-4e80-ae26-a9cde884356b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:39:52.412017Z",
     "iopub.status.busy": "2025-04-21T19:39:52.411896Z",
     "iopub.status.idle": "2025-04-21T19:39:52.415165Z",
     "shell.execute_reply": "2025-04-21T19:39:52.414401Z",
     "shell.execute_reply.started": "2025-04-21T19:39:52.412007Z"
    }
   },
   "outputs": [],
   "source": [
    "# LoRA 配置\n",
    "peft_config = LoraConfig(\n",
    "    r=8,  # 秩\n",
    "    lora_alpha=16,  # 缩放系数\n",
    "    lora_dropout=0.05,  # dropout 比例\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"\n",
    "    ],  # 指定需要微调的模块\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e664e-3620-4df1-a479-35f933d78f01",
   "metadata": {},
   "source": [
    "`SFTConfig` 的配置也压低了单卡批量数和训练轮次，因为我们旨在跑通，并非正经训练。\n",
    "\n",
    "如果你想了解更多 `SFTConfig` 的配置详情，请参考文档：[trl.SFTConfig](https://huggingface.co/docs/trl/sft_trainer#trl.SFTConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b13895-f1a2-4c44-b272-07a3dac4fa95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:39:52.416042Z",
     "iopub.status.busy": "2025-04-21T19:39:52.415773Z",
     "iopub.status.idle": "2025-04-22T00:27:29.518791Z",
     "shell.execute_reply": "2025-04-22T00:27:29.517442Z",
     "shell.execute_reply.started": "2025-04-21T19:39:52.416030Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/canva/miniconda3/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:413: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 4:46:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.372700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.936900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.338500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.058200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.975400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.796700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.132900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.244900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.166500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.241200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.037800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.082900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.940600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.958200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=2.0678365478515626, metrics={'train_runtime': 17254.0699, 'train_samples_per_second': 0.058, 'train_steps_per_second': 0.058, 'total_flos': 6216113574236160.0, 'train_loss': 2.0678365478515626, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SFT 训练参数\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./Qwen2.5-0.5B-SFT\",\n",
    "    per_device_train_batch_size=1,  # 单卡批量数\n",
    "    num_train_epochs=1,  # 训练轮次。这里仅仅为了跑通，因此设为 1\n",
    "    fp16=True,  # 启用半精度训练\n",
    "    optim=\"adamw_torch_fused\",  # 使用内存优化的优化器\n",
    "    max_seq_length=512,  # 序列的最大长度\n",
    "    logging_steps=50,  # 日志打印间隔，默认 500\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset,\n",
    "    args=training_args,\n",
    "    peft_config=peft_config,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00da6dde-baed-487c-82bf-a33a1877d38e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T04:20:46.644899Z",
     "iopub.status.busy": "2025-04-22T04:20:46.644398Z",
     "iopub.status.idle": "2025-04-22T04:20:47.515553Z",
     "shell.execute_reply": "2025-04-22T04:20:47.515024Z",
     "shell.execute_reply.started": "2025-04-22T04:20:46.644875Z"
    }
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be3212-bf6b-4ded-bfa8-892a4b7c2279",
   "metadata": {},
   "source": [
    "## 3. 加载微调后的模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82231c5-dd45-4b53-a603-c2e574633077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T05:01:22.557020Z",
     "iopub.status.busy": "2025-04-22T05:01:22.556794Z",
     "iopub.status.idle": "2025-04-22T05:07:26.853344Z",
     "shell.execute_reply": "2025-04-22T05:07:26.852548Z",
     "shell.execute_reply.started": "2025-04-22T05:01:22.557007Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6ef68b56c24836b885cb6c31f450af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"./Qwen2.5-0.5B-SFT\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./Qwen2.5-0.5B-SFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5f31c6f-ab6d-4838-bb13-a50f083bd80c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T05:20:19.919715Z",
     "iopub.status.busy": "2025-04-22T05:20:19.918802Z",
     "iopub.status.idle": "2025-04-22T05:21:43.435769Z",
     "shell.execute_reply": "2025-04-22T05:21:43.435291Z",
     "shell.execute_reply.started": "2025-04-22T05:20:19.919693Z"
    }
   },
   "outputs": [],
   "source": [
    "def use_template(text):\n",
    "    return f'### Question: {text}\\n ### Answer:'\n",
    "\n",
    "query = use_template(text='癔症有哪些表现')\n",
    "inputs = tokenizer(query, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a881b5e9-fcbc-4bbd-9dd3-7379a4e28ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T05:21:43.436447Z",
     "iopub.status.busy": "2025-04-22T05:21:43.436342Z",
     "iopub.status.idle": "2025-04-22T05:21:43.442892Z",
     "shell.execute_reply": "2025-04-22T05:21:43.442477Z",
     "shell.execute_reply.started": "2025-04-22T05:21:43.436440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 14374,  15846,     25,  68294,    242,  99769, 104719, 101107,    198,\n",
       "          16600,  21806,     25,    220,     16,   5373, 121998,  99769,  33071,\n",
       "         113098, 119442,   5122, 101924, 100347, 115230,  57191,  99493,  99772,\n",
       "         114961, 113098, 119442,   3837,  30440, 115563, 100681, 102544,   1773,\n",
       "             17,   5373, 121998,  99769,  33071,  20726,  30858,   5122, 101924,\n",
       "         103961, 110632, 112067, 108784,   3837,  77288, 113563, 101071,  38342,\n",
       "          99879,  70633,   1773,     18,   5373, 121998,  99769,  33071]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e37399a2-11db-4f88-b996-4a0e8af375ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T05:25:44.622129Z",
     "iopub.status.busy": "2025-04-22T05:25:44.621807Z",
     "iopub.status.idle": "2025-04-22T05:25:44.626411Z",
     "shell.execute_reply": "2025-04-22T05:25:44.625770Z",
     "shell.execute_reply.started": "2025-04-22T05:25:44.622108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Question: 癔症有哪些表现\\n ### Answer: 1、癔症性瘫痪：患者出现一侧或双侧肢体瘫痪，可伴有感觉障碍。2、癔症性失明：患者突然双眼视力丧失，但眼科检查未发现异常。3、癔症性'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca5727-ec52-4739-99b5-5052e212272b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T16:00:24.469917Z",
     "iopub.status.busy": "2025-04-16T16:00:24.468671Z",
     "iopub.status.idle": "2025-04-16T16:00:24.513806Z",
     "shell.execute_reply": "2025-04-16T16:00:24.512013Z",
     "shell.execute_reply.started": "2025-04-16T16:00:24.469495Z"
    }
   },
   "source": [
    "参考：\n",
    "\n",
    "- trl SFT 文档：[Supervised Fine-tuning Trainer](https://huggingface.co/docs/trl/sft_trainer)\n",
    "- trl 示例：[sft.py](https://github.com/huggingface/trl/blob/main/trl/scripts/sft.py)\n",
    "- peft 文档：[peft](https://huggingface.co/docs/peft/index)\n",
    "- [知乎：使用HuggingFace TRL微调Qwen1.5-7B模型（SFT）](https://zhuanlan.zhihu.com/p/692013471)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ef1a7-a077-455c-b13c-b0d6cffa7415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
